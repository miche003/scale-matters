{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                              # import numerical python\n",
    "import matplotlib.pyplot as plt                                 # import plot library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Matters\n",
    "A study into the 'fairness' of scaling large-scale assessments <br>\n",
    "By: Gerard Barkema, Matthieu Brinkhuis & Berenice Michels\n",
    "\n",
    "## Simulating a large-scale test\n",
    "We simulate a test adminstered to *N* students, consisting of *M* items. <br>\n",
    "The test is meant to measure a latent ability of the students $\\theta$ which we assume to be normally distributed around a mean value <$\\theta$> with a standard deviation $\\sigma_\\theta$. \n",
    "\n",
    "> simulation: change N, M, <$\\theta$>, $\\sigma_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE: define population_length as array length for population (N) \n",
    "# CHOOSE: and test_length as array lenght for test (M)\n",
    "population_length = 10000                                       #N\n",
    "test_length = 100                                             #M\n",
    "\n",
    "# CHOOSE mean and standard deviation for ability \n",
    "ability_mean = 0.0                                              # theta_mean\n",
    "ability_stddev = 1.0                                            # sigma_theta\n",
    "\n",
    "# fill ability array\n",
    "ability = np.random.normal(ability_mean,ability_stddev,population_length)\n",
    "                                                                # array with random normally distributed abilities\n",
    "ability_org = ability.copy()\n",
    "#plt.hist(ability_org,bins=int(population_length/10))\n",
    "#plt.xlabel(\"ability\")\n",
    "#plt.ylabel(\"number of students\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to simulate a situation where part of the examinees gets 'better' (probably through extra education).<br>\n",
    "In that case select: subsample = \"Yes\" <br> <br>\n",
    "We divide the whole range of abilities in subsamples, defined by the distance to the mean.\n",
    "The subsamples have a width of *n*$\\sigma_\\theta$, where *n* can be set. <br>\n",
    "All abilities can be adjusted, or only part of the array, given by the number of items to take out of another (larger or same) number of items. <br>\n",
    "The lower and upper border of the abilities that are to be corrected are given through edu_min and edu_max. Both will be multiplied with the width of the subsample and than added to the mean (so use negative numbers if you want to adjus the abilities below the mean.<br>\n",
    "Finally, the effect of the extra education is represented by an amplification factor, relative to the standard deviation.\n",
    "> simulation: sub (=width of subsample); take and out_of; edu_min and edu_max; amplif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = True\n",
    "\n",
    "# If True: define the width of the subsamples (as fraction of the standard deviation)\n",
    "sub = 0.5                                        # width of subsample = sub*ability_stddev\n",
    "\n",
    "# if True: define the portion of the subsamples to be 'educated extra'\n",
    "# take = 1 out_of 3 means 1/3 is educated extra\n",
    "take = 2\n",
    "out_of = 3\n",
    "portion = take/out_of\n",
    "\n",
    "# If True: define what subsample(s) receives extra education'\n",
    "# edu_min*sub*ability_stddev is the lower border of the students educated extra, \n",
    "# edu_max*sub*ability_stddev the upper border, borders not included\n",
    "edu_min = -2.0\n",
    "edu_max = +0.0\n",
    "\n",
    "ability_min = ability_mean + (edu_min*sub*ability_stddev)\n",
    "ability_max = ability_mean + (edu_max*sub*ability_stddev)\n",
    "# print(ability_min, ability_max)\n",
    "\n",
    "# If True: define the increment of ability due to the extra education\n",
    "amplif = 1.0\n",
    "\n",
    "edu_effect = amplif*ability_stddev\n",
    "\n",
    "#if subsample:\n",
    "#    for (x) in range(population_length):\n",
    "#         if (ability[x] > ability_min) & (ability[x] < ability_max):\n",
    "#                ability[x] = ability[x] + edu_effect\n",
    "\n",
    "#print(ability_min,ability_max)\n",
    "if subsample:\n",
    "    n = 0\n",
    "    while n < population_length:\n",
    "        for (x) in range(out_of):\n",
    "#            print(\"x = \",x)\n",
    "            for y in range(take):\n",
    "                if n < population_length:\n",
    "#                    print(\"y = \",y)\n",
    "#                    print(\"n = \",n)\n",
    "#                    print(ability[n])\n",
    "                    if ((ability[n] > ability_min) & (ability[n] < ability_max)):\n",
    "#                        print(\"check\")\n",
    "                        ability[n] = ability[n] + edu_effect\n",
    "#                        print(ability[n])\n",
    "                    n = n+1\n",
    "            n = n+(out_of-take)\n",
    "#            print(\"n = \",n)\n",
    "#        \n",
    "#        print(out_of)\n",
    "#        print(ability[x])\n",
    "    \n",
    "#plt.hist(ability,bins=int(population_length/10))\n",
    "#plt.xlabel(\"ability\")\n",
    "#plt.ylabel(\"number of students\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item *i* has a difficulty $\\beta_i$. In accordance with general Item Response Theory (e.g. DeMars, 2010) the difficulty identifies the ability at which 50% of the students, taking the test, is expected to give a correct answer to the question. $\\theta$ and $\\beta$ are defined on the same metric. \n",
    "We can set the mean and standard deviation of the difficulty of the items in the test in comparison to that of the student's ability: $\\Delta_\\theta$ and $\\Delta_\\sigma$.\n",
    "\n",
    "> simulation: change ŒîùúÉ and Œîùúé <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE mean and standard deviation for difficulty (in relation to the ability values)\n",
    "mean_dif = 0.0                                              # Delta_theta\n",
    "stddev_dif = -0.5                                            # Delta_sigma\n",
    "width = 4.0                                                 # for uniform distributions, set to 4*stddev of beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simulating the test, we assume that the probability *P* that student *i*  answers question *k*\n",
    "correctly (and obtaines a score of 1), is given by the 1PL Item Response Function\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "\\begin{equation}\n",
    "P_{ik}=\\frac{\\exp((\\theta_i-\\beta_k)/\\alpha)}{1+\\exp((\\theta_i-\\beta_k)/\\alpha))}\n",
    "\\end{equation}\n",
    "%\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is a constant, denoting the discrimination of the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function IRF\n",
    "def IRF(L,M,theta,beta,alfa):\n",
    "#    L: integer - population size\n",
    "#    M: integer - number of test items\n",
    "#    theta: 2d-array of floats; shape (L,M) - abilities\n",
    "#    beta = 2d-array of floats; shape (L,M) - difficulties\n",
    "#    alfa = float - constant\n",
    "    D = (theta - beta)/alfa\n",
    "    IRF = np.exp(D)/(1+np.exp(D))\n",
    "    return(IRF)\n",
    "\n",
    "# CHOOSE alpha\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the test. \n",
    "We simulate that the population of students with ability $\\theta$ takes the test with difficulties $\\beta$.\n",
    "We can run the simulation a number of times and average the outcomes\n",
    "\n",
    "- set the number of tests we want to sample\n",
    "- choose the distribution of the difficulties: normally random, uniformly random or uniformly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE number of iterations\n",
    "sample = 1                                                   # number of iterations\n",
    "\n",
    "P_test_score = np.zeros(population_length)\n",
    "test_score = np.zeros(population_length)\n",
    "p_values_test = np.zeros(test_length)\n",
    "\n",
    "# set the difficulty mean and stddev\n",
    "difficulty_mean = ability_mean + mean_dif                       # calculated mean of difficulties\n",
    "difficulty_stddev = ability_stddev + stddev_dif                 # calculated standard deviation of difficulties\n",
    "print(difficulty_mean, difficulty_stddev)\n",
    "\n",
    "# start loop through 'sample' iterations\n",
    "for x in range(sample):\n",
    "#    print(x)\n",
    "\n",
    "    \n",
    "# CHOOSE distribution of difficulty\n",
    "    \n",
    "    difficulty = np.random.normal(difficulty_mean, difficulty_stddev, test_length)                                                            # array with random **normally** distributed difficulties\n",
    "   \n",
    "    # difficulty = np.random.uniform(low=difficulty_mean-width,high=difficulty_mean+width,size=test_length)\n",
    "                                                              # array with random **uniformly** distributed difficulties\n",
    "    \n",
    "    #  difficulty = np.linspace(difficulty_mean-width,difficulty_mean+width,num=test_length,endpoint=True)\n",
    "                                                              # array with linear **uniformly** distributed difficulties\n",
    "    \n",
    "#    plt.hist(difficulty_x, bins=int(test_length/10))\n",
    "#    plt.xlabel(\"difficulty\")\n",
    "#    plt.ylabel(\"number of items\");\n",
    "     \n",
    "#Calculate the probability of a correct score for every combination of student *i* and item *k*\n",
    "    rs_ability = ability.reshape(population_length,1)\n",
    "    rs_difficulty = difficulty.reshape(1,test_length)\n",
    "    P_testresult=IRF(population_length,test_length,rs_ability,rs_difficulty,alpha)\n",
    "#    print(rs_ability)\n",
    "#    print(P_testresult)\n",
    "\n",
    "# Calculate the testscore per student based on the probabilities per item\n",
    "    P_test_score_x = np.sum(P_testresult,axis=1)\n",
    "    P_test_score = P_test_score + P_test_score_x\n",
    "\n",
    "# Determine for every student - item combination whether the student answers the item correctly (P>=0,5) or false (P<0.5)\n",
    "#    testresult = np.rint(P_testresult)\n",
    " \n",
    "# Determine for every student - item combination whether the student answers the item correctly:\n",
    "# compare each probability P to a random generated probability R (uniform), \n",
    "# if P >= R the item score = 1; if P < R the item score = 0\n",
    "    rand_compare = np.random.uniform(low=0,high=1,size=(population_length,test_length))\n",
    "#    print(rand_compare)\n",
    "#    print()\n",
    "#    print(P_testresult)\n",
    "    compare = P_testresult+1-rand_compare\n",
    "#    print()\n",
    "#    print(compare)\n",
    "    testresult = np.trunc(compare)\n",
    "#    print()\n",
    "#    print(testresult)\n",
    "\n",
    "    \n",
    "# Calculate the testscore per student based on the item being correct (=1) or incorrect (=0)\n",
    "    test_score_x = np.sum(testresult,axis=1)\n",
    "    test_score = test_score + test_score_x\n",
    "#    print()\n",
    "#    print(test_score)\n",
    "    \n",
    "# Calculate the P-value per testitem based on the item being correct (=1) or incorrect (=0)\n",
    "    p_values_test_x = np.sum(testresult,axis=0)\n",
    "    p_values_test_x = p_values_test_x/population_length\n",
    "    p_values_test = p_values_test + p_values_test_x\n",
    "\n",
    "P_test_score = P_test_score/sample\n",
    "test_score = test_score/sample\n",
    "p_values_test = p_values_test/sample\n",
    "sorted_p_values = np.sort(p_values_test)\n",
    "sorted_p_values_x = np.sort(p_values_test_x)\n",
    "\n",
    "# test_avg = np.average(test_score)\n",
    "test_mean = np.mean(test_score)\n",
    "test_std = np.std(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the results - linear transformation\n",
    "\n",
    "scale_min = 500\n",
    "scale_max = 550\n",
    "\n",
    "scale_length = scale_max - scale_min\n",
    "# print(scale_length)\n",
    "\n",
    "scaled_score = (test_score/test_length)*scale_length + scale_min\n",
    "scaled_mean = np.mean(scaled_score)\n",
    "scaled_std = np.std(scaled_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print output\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(421)\n",
    "plt.hist(ability_org,bins=int(population_length/10))\n",
    "plt.xlabel(\"ability uncorrected\")\n",
    "plt.ylabel(\"number of students\");\n",
    "\n",
    "if subsample:\n",
    "    plt.subplot(422)\n",
    "    plt.hist(ability,bins=int(population_length/10))\n",
    "    plt.xlabel(\"ability new\")\n",
    "    plt.ylabel(\"number of students\");\n",
    "\n",
    "plt.subplot(423)\n",
    "plt.hist(difficulty, bins=int(test_length/10))\n",
    "plt.xlabel(\"difficulty\")\n",
    "plt.ylabel(\"number of items\");\n",
    "\n",
    "plt.subplot(425)\n",
    "plt.hist(test_score,bins=int(test_length))\n",
    "plt.xlabel(\"test score\")\n",
    "plt.ylabel(\"number of students\");\n",
    "\n",
    "plt.subplot(426)\n",
    "plt.hist(scaled_score,bins=int(test_length))\n",
    "plt.xlabel(\"scaled score\")\n",
    "plt.ylabel(\"number of students\");\n",
    "\n",
    "plt.subplot(427)\n",
    "plt.hist(p_values_test,bins=20,range=(0,1))\n",
    "plt.xlabel(\"p_values\")\n",
    "plt.ylabel(\"number of questions\");\n",
    "\n",
    "plt.subplot(428)\n",
    "plt.plot(sorted_p_values)\n",
    "plt.xlabel(\"number of questions\")\n",
    "plt.ylabel(\"p_values\");\n",
    "\n",
    "print(\"N = %.i   M = %.i\"%(population_length,test_length))\n",
    "print(\"mean ability = %.1f    standdard deviation ability = %.2f\"%(ability_mean,ability_stddev))\n",
    "print(\"mean difficulty = %.1f   standdard deviation difficulty = %.2f   width distribution difficulty = %.1f\"\n",
    "      %(difficulty_mean,difficulty_stddev,width))\n",
    "if subsample:\n",
    "    print(\"abilities corr. between %.2f and %.2f, portion of population corrected = %.2f, amplification = %.2f \"\n",
    "          %(edu_min,edu_max,portion,edu_effect))\n",
    "print()\n",
    "print(\"number of samples: %.i\"%(sample))\n",
    "print(\"mean score = %.2f  standard deviation = %.2f\"%(test_mean,test_std))\n",
    "print(\"mean scaled score = %.2f  standard deviation scaled = %.2f\"%(scaled_mean,scaled_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
